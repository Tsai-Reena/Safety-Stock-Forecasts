{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f338fc65",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_02 = pd.read_excel('Mighty_ABC_DATA 2020-2021.xlsx', '庫存計畫表')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = data_02[data_02['VendorCode'] == 'VP021']\n",
    "data_VD005.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = data_VD005.drop(['VendorCode'], axis=1, inplace=False)\n",
    "data_VD005.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ed0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = data_VD005.iloc[:-1].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3701a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005.head(5)\n",
    "col = data_VD005['PartNumber']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aeb9ec",
   "metadata": {},
   "source": [
    "### Transposing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = np.transpose(data_VD005[['2020/02/01', '2020/03/01', '2020/04/01',\n",
    "                         '2020/05/01', '2020/06/01', '2020/07/01',\n",
    "                         '2020/08/01', '2020/09/01', '2020/10/01',\n",
    "                         '2020/11/01', '2020/12/01', '2021/01/01',\n",
    "                         '2021/02/01', '2021/03/01', '2021/04/01',\n",
    "                         '2021/05/01', '2021/06/01', '2021/07/01']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005.columns = col\n",
    "index = data_VD005.index\n",
    "data_VD005.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc27eeb",
   "metadata": {},
   "source": [
    "### Data Normalizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = preprocessing.normalize(data_VD005)\n",
    "print(\"Normalized Data = \", data_VD005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec5f30",
   "metadata": {},
   "source": [
    "### Data Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x_scale = preprocessing.scale(data_VD005)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc294f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005 = pd.DataFrame(x_scale)\n",
    "data_VD005.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d23dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005.index = index\n",
    "data_VD005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VD005.insert(0, 'Date', data_VD005.index)\n",
    "data_VD005.reset_index(inplace=True, drop=True)\n",
    "data_VD005.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b86b7",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證函數\n",
    "from numpy import array\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea889e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b7717",
   "metadata": {},
   "source": [
    "### Shift the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前面天數會有NAN\n",
    "ss_VD005 = data_VD005[['1-64-13325-00671H']][:100]\n",
    "ss_VD005['s-5'] = ss_VD005['1-64-13325-00671H'].shift(5)\n",
    "ss_VD005['s-4'] = ss_VD005['1-64-13325-00671H'].shift(4)\n",
    "ss_VD005['s-3'] = ss_VD005['1-64-13325-00671H'].shift(3)\n",
    "ss_VD005['s-2'] = ss_VD005['1-64-13325-00671H'].shift(2)\n",
    "ss_VD005['s-1'] = ss_VD005['1-64-13325-00671H'].shift(1)\n",
    "ss_VD005['s-0'] = ss_VD005['1-64-13325-00671H']\n",
    "ss_VD005.drop(columns='1-64-13325-00671H', inplace=True)\n",
    "ss_VD005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證數據\n",
    "# 前面幾次的數據 n_in 去預測後面幾次的數據 n_out\n",
    "predict_months = 2\n",
    "values = data_VD005['1-64-13325-00671H'].tolist()\n",
    "data2 = series_to_supervised(values, n_in=predict_months, n_out=1, dropnan=True) #*************優化過去幾天 預測下一天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef682ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eecef1",
   "metadata": {},
   "source": [
    "### Split the data into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68586454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出 X , y\n",
    "X = data2.iloc[:, [0,1,2]].values\n",
    "y = data2.iloc[:, [-1]].values\n",
    "# 資料切割 \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb11a2a",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 BILSTM 看前看後記憶\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "n_steps = 3\n",
    "n_features = 1\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(n_steps, n_features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd332980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(X, y, epochs=500, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e8155",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.grid()\n",
    "plt.plot( history.history.get('loss') , color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Deep Learning 進行預測\n",
    "# 重要數據\n",
    "pre_Close = model.predict(X).ravel()\n",
    "Close = y\n",
    "\n",
    "np.sum((pre_Close - Close)**2) / len(Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss (history, model_name):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Train vs Validation Loss for ' + model_name)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
    "\n",
    "plot_loss (history, 'Bidirectional LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a787c9",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test data vs prediction\n",
    "def plot_future(prediction, model_name, y_test):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    range_future = len(prediction)\n",
    "\n",
    "    plt.plot(np.arange(range_future), np.array(y_test), label='Test data')\n",
    "    plt.plot(np.arange(range_future), np.array(prediction),label='Prediction')\n",
    "\n",
    "    plt.title('Test data vs prediction for ' + model_name)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Time (month)')\n",
    "    plt.ylabel('Safety stock consumption ($m^3$/capita.month)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd132ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "plot_future(predictions, 'Bidirectional LSTM', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
